{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deNc-p1pJ-o-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv ('data_Ithaca.csv')\n",
        "data = df.values\n",
        "# 5th column for ground truth solar, 20th column for disaggregated solar\n",
        "# to include GHI, add 9th column\n",
        "names = df.columns[[5,10,23,24,25,26,6,27,0,2,22]]\n",
        "# names = df.columns[[5,10,23,24,25,26,6,27,9,0,2,22]]\n",
        "print(names)\n",
        "data = data[:,[5,10,23,24,25,26,6,27,0,2,22]]\n",
        "mean_s, std_s, min_s, max_s = np.mean(data[:,0]), np.std(data[:,0]), np.min(data[:,0]), np.max(data[:,0])\n",
        "print('mean',mean_s, 'std',std_s, 'max',max_s, 'min',min_s)\n",
        "# normalize entire dataset to [0,1]\n",
        "data[:,0] = (data[:,0]-min_s)/(max_s-min_s)\n",
        "data = data.astype('float32')\n",
        "for i in [1,2,3,4,5,6,7]:\n",
        "    min_temp, max_temp = np.min(data[:,i]), np.max(data[:,i]) \n",
        "    data[:,i] = (data[:,i]-min_temp)/(max_temp-min_temp)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "xvIny4JHKL9E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# employ sliding window to stack data correspondingly\n",
        "def Create_dataset(dataset):\n",
        "    data_X, data_Y, data_Z = [], [], []\n",
        "    dt = dataset.tolist()\n",
        "    for i in range(len(dataset)-820): \n",
        "        temp = dataset[i+724:i+820,:]\n",
        "        temp1 = temp[:,0].reshape(-1,1)\n",
        "        temp2 = temp[:,1:8].reshape(-1,1)\n",
        "#         temp2 = temp[:,1:9].reshape(-1,1) # including GHI\n",
        "        temp3 = temp[:,8:].reshape(-1,1) \n",
        "#         temp3 = temp[:,9:].reshape(-1,1)  # including GHI\n",
        "       \n",
        "        data_X.append(temp2)\n",
        "        data_Y.append(temp1)\n",
        "        data_Z.append(temp3)\n",
        "    \n",
        "    return np.array(data_X), np.array(data_Y), np.array(data_Z)"
      ],
      "metadata": {
        "id": "XMNKnAsSKTYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode categorical input features\n",
        "# omit weekday here as it's irrelevent to solar generation\n",
        "one_hot = lambda label,num_classes: F.one_hot(label.long(), num_classes=num_classes).type(torch.float32)\n",
        "cycl_ = lambda x,num_classes : torch.tensor((np.sin(x / num_classes * 2 * np.pi),np.cos(x / num_classes * 2 * np.pi))).type(torch.float32)\n",
        "\n",
        "def Calender(ty):\n",
        "    calender = []\n",
        "    for i in range(ty.shape[0]):\n",
        "        tty = ty[i]\n",
        "        temp = torch.zeros(96,12)\n",
        "        for j in range(96):\n",
        "            H = torch.unsqueeze(cycl_(tty[3*j+1],96),0)\n",
        "            C = one_hot(tty[3*j+2],10)\n",
        "            temp[j,:] = torch.cat((H,C),1)\n",
        "        temp = temp.reshape(1,-1)  \n",
        "        calender.append(temp.tolist())\n",
        "    return torch.tensor(calender)"
      ],
      "metadata": {
        "id": "6boxxW17MTT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evenly divide the whole dataset into five folds for cross validation\n",
        "test_indice1 = list(range(0,672))+list(range(3360,3360+672))+list(range(3360*2,3360*2+672))+list(range(3360*3,3360*3+672))+list(range(3360*4,3360*4+672))\n",
        "test_indice2 = list(range(672,672*2))+list(range(3360+672,3360+672*2))+list(range(3360*2+672,3360*2+672*2))+list(range(3360*3+672,3360*3+672*2))+list(range(3360*4+672,3360*4+672*2))\n",
        "test_indice3 = list(range(672*2,672*3))+list(range(3360+672*2,3360+672*3))+list(range(3360*2+672*2,3360*2+672*3))+list(range(3360*3+672*2,3360*3+672*3))+list(range(3360*4+672*2,3360*4+672*3))\n",
        "test_indice4 = list(range(672*3,672*4))+list(range(3360+672*3,3360+672*4))+list(range(3360*2+672*3,3360*2+672*4))+list(range(3360*3+672*3,3360*3+672*4))+list(range(3360*4+672*3,3360*4+672*4))\n",
        "test_indice5 = list(range(672*4,672*5))+list(range(3360+672*4,3360+672*5))+list(range(3360*2+672*4,3360*2+672*5))+list(range(3360*3+672*4,3360*3+672*5))+list(range(3360*4+672*4,3360*4+672*5))\n",
        "train_indice = list(range(0,16844))"
      ],
      "metadata": {
        "id": "M8LLdJ7cM5hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate input features data_X and output labels data_Y\n",
        "data_X, data_Y, data_Z = Create_dataset(data)\n",
        "data_Z = np.array(Calender(torch.tensor(data_Z)))\n",
        "data_Z = np.transpose(data_Z,(0,2,1))\n",
        "data_X = np.concatenate((data_X,data_Z),1)"
      ],
      "metadata": {
        "id": "D5QjjYAMMzm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate training data and testing data respectively for each one of the five folds\n",
        "train_X, test_X = [data_X[index] for index in train_indice if index not in test_indice1], [data_X[index] for index in test_indice1]\n",
        "train_Y, test_Y = [data_Y[index] for index in train_indice if index not in test_indice1], [data_Y[index] for index in test_indice1]\n",
        "train_X, train_Y = np.array(train_X), np.array(train_Y)\n",
        "test_X, test_Y = np.array(test_X), np.array(test_Y)"
      ],
      "metadata": {
        "id": "KMDjP_H5NF4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Train(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.weather, self.calender, self.label = data[:,:672,:].float(), data[:,672:1824,:].float(), data[:,-96:,:].float()\n",
        "#         self.weather, self.calender, self.label = data[:,:768,:].float(), data[:,768:1920,:].float(), data[:,-96:,:].float() # including GHI\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.weather[index], self.calender[index], self.label[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.weather)"
      ],
      "metadata": {
        "id": "rB4hE4vzNUxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load training data into DataLoader\n",
        "train_loader = DataLoader(Train(torch.cat((torch.tensor(train_X),torch.tensor(train_Y)),1)), batch_size=500, shuffle=True)"
      ],
      "metadata": {
        "id": "p4EKZ6yUNd5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FCNN model\n",
        "class ANN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ANN, self).__init__()\n",
        "        \n",
        "        self.ann = nn.Sequential(\n",
        "            nn.Linear(19,40),\n",
        "            # nn.Linear(20,40), # including GHI\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(40,1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, z):\n",
        "        \n",
        "        batch = x.shape[0]\n",
        "        x = torch.reshape(x,(batch,96,-1))        \n",
        "        z = torch.reshape(z,(batch,96,-1))\n",
        "        xz = torch.cat((x,z),2)\n",
        "        txz = self.ann(xz) \n",
        "        out = self.out(txz)\n",
        "        return out"
      ],
      "metadata": {
        "id": "-lDAA9gANj6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters for training process\n",
        "LR = 0.01\n",
        "EPOCH = 500\n",
        "Loss = []\n",
        "best_loss = 100\n",
        "state = None\n",
        "cal_loss = nn.MSELoss()"
      ],
      "metadata": {
        "id": "oTvDz5OvPMPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training FCNN model\n",
        "model = ANN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR) \n",
        "for i in range(EPOCH):\n",
        "    for j, entry in enumerate(train_loader):\n",
        "        tx, ty, tz = entry\n",
        "        tx = torch.transpose(tx,1,2)\n",
        "        ty = torch.transpose(ty,1,2)\n",
        "        final_out = model(tx,ty)\n",
        "        loss = cal_loss(final_out, tz)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "        Loss.append(loss.detach().numpy())\n",
        "    print('epoch{}'.format(i+1), loss.detach().numpy())\n",
        "    if loss.detach().numpy() < best_loss:\n",
        "        best_loss = loss.detach().numpy()\n",
        "        torch.save(model, 'ithaca_solar'.format(loss.detach().numpy()))\n",
        "        print('new fcnn saved at epoch {} with loss {}'.format(i+1, best_loss))"
      ],
      "metadata": {
        "id": "lAafPUyzPXha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,6))\n",
        "plt.plot(Loss,'b')\n",
        "plt.title('Training Loss for Solar',fontsize=15)\n",
        "plt.savefig('training_loss.png')"
      ],
      "metadata": {
        "id": "RKRH1EucXlgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate prediction for testing set with trained fcnn model\n",
        "model = torch.load('ithaca_solar')\n",
        "model.eval()\n",
        "test_weather = test_X[:,:672,:]\n",
        "test_weather = torch.tensor(test_weather, dtype=torch.float32)\n",
        "test_weather = torch.transpose(test_weather,1,2)\n",
        "test_date = test_X[:,672:,:]\n",
        "test_date = torch.tensor(test_date, dtype=torch.float32)\n",
        "prediction = model(test_weather,test_date)\n",
        "torch.save(prediction, 'prediction_solar.pt')"
      ],
      "metadata": {
        "id": "HK91LPcKPkeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate input features with simulated GHI\n",
        "mu, sigma = 0, 10\n",
        "error = np.random.normal(mu, sigma, 17664)\n",
        "# ensure zero GHI for timeslots without sunlight\n",
        "indice = np.where(data[:,8]==0)\n",
        "error[indice] = 0\n",
        "data[:,8] += error\n",
        "# ensure positive simulated GHI\n",
        "data[:,8] = np.where(data[:,8]>0, data[:,8], data[:,8]==0)"
      ],
      "metadata": {
        "id": "a9gP09VpXiFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_X_sim, _, _ = Create_dataset(data)\n",
        "data_XX = np.concatenate((data_X_sim,data_Z),1)\n",
        "test_X_sim = [data_XX[index] for index in test_indice1]\n",
        "test_X_sim = np.array(test_X_sim)"
      ],
      "metadata": {
        "id": "eIShRUWrZBC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate prediction for testing set with trained fcnn model, \n",
        "# which incorporates ground truth GHI as input feature during training\n",
        "model = torch.load('ithaca_solar_GHI')\n",
        "model.eval()\n",
        "test_weather = test_X_sim[:,:768,:]\n",
        "test_weather = torch.tensor(test_weather, dtype=torch.float32)\n",
        "test_weather = torch.transpose(test_weather,1,2)\n",
        "test_date = test_X_sim[:,768:,:]\n",
        "test_date = torch.tensor(test_date, dtype=torch.float32)\n",
        "prediction_GHI = model(test_weather,test_date)\n",
        "torch.save(prediction, 'prediction_solar_GHI.pt')"
      ],
      "metadata": {
        "id": "V-yoKJM_ZPqC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}