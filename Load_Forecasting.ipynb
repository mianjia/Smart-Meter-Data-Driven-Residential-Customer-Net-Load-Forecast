{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha2gNdZq2SoB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv ('data_Ithaca.csv')\n",
        "data = df.values\n",
        "# 13th column for ground truth load, 29th column for disaggregated load\n",
        "names = df.columns[[13,10,23,24,25,26,6,27,0,2,22]]\n",
        "print(names)\n",
        "data = data[:,[13,10,23,24,25,26,6,27,0,2,22]]\n",
        "mean_c, std_c, min_c, max_c = np.mean(data[:,0]), np.std(data[:,0]), np.min(data[:,0]), np.max(data[:,0])\n",
        "print('mean',mean_c, 'std',std_c, 'max',max_c, 'min',min_c)\n",
        "# normalize entire dataset to [0,1]\n",
        "data[:,0] = (data[:,0]-min_c)/(max_c-min_c)\n",
        "data = data.astype('float32')\n",
        "for i in [1,2,3,4,5,6,7]:\n",
        "    min_temp, max_temp = np.min(data[:,i]), np.max(data[:,i]) \n",
        "    data[:,i] = (data[:,i]-min_temp)/(max_temp-min_temp)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2KHgxBZ2dKM",
        "outputId": "987c586a-459a-4cdb-e92f-b036fc7cdc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['consumption', 'Temperature', 'Dew Point', 'Wind Speed.1',\n",
            "       'Precipitable Water', 'Relative humidity', 'zenith', 'Pressure',\n",
            "       'weekday', 'timeslot of day', 'Cloud Type'],\n",
            "      dtype='object')\n",
            "mean 10.385668138586956 std 4.49667223574142 max 37.726 min 3.298\n",
            "(17664, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# employ sliding window to stack data correspondingly\n",
        "def Create_dataset(dataset):\n",
        "    data_X, data_Y, data_Z, data_W = [], [], [], []\n",
        "    dt = dataset.tolist()\n",
        "    for i in range(len(dataset)-820): \n",
        "        indice = list(range(i,i+96))+list(range(i+96*5,i+96*7))\n",
        "        tempx = np.array([dt[index] for index in indice])\n",
        "        tempy = dataset[i+724:i+820,:]\n",
        "        tempw = dataset[i:i+96,:]\n",
        "        temp1 = tempx[:,0].reshape(-1,1)\n",
        "        temp2 = tempy[:,1:8].reshape(-1,1)\n",
        "        temp3 = np.concatenate((temp1,temp2)).tolist()\n",
        "        temp4 = tempy[:,0].tolist()\n",
        "        temp5 = tempy[:,8:].reshape(-1,1)\n",
        "        temp6 = tempw[:,0].reshape(-1,1)\n",
        "       \n",
        "        data_W.append(temp6) # load traces from the day one week ago\n",
        "        data_X.append(temp3) # load traces from the past two days and numerical weather forecast\n",
        "        data_Y.append(temp4) # targeted load traces (13 hours ahead ~ 37 hours ahead)\n",
        "        data_Z.append(temp5) # categorical features\n",
        "    \n",
        "    return np.array(data_X), np.array(data_Y), np.array(data_Z), np.array(data_W)"
      ],
      "metadata": {
        "id": "-zc2kFMW2uiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode categorical input features\n",
        "one_hot = lambda label,num_classes: F.one_hot(label.long(), num_classes=num_classes).type(torch.float32)\n",
        "cycl_ = lambda x,num_classes : torch.tensor((np.sin(x / num_classes * 2 * np.pi),np.cos(x / num_classes * 2 * np.pi))).type(torch.float32)\n",
        "\n",
        "def Calender(data):\n",
        "    calender = []\n",
        "    for i in range(data.shape[0]):\n",
        "        ty = data[i]\n",
        "        temp = torch.zeros(96,19)\n",
        "        for j in range(96):\n",
        "            W = one_hot(ty[3*j]-1,7)                   # weekday\n",
        "            H = torch.unsqueeze(cycl_(ty[3*j+1],24),0) # timeslot of the day\n",
        "            C = one_hot(ty[3*j+2],10)                  # cloud type\n",
        "            temp[j,:] = torch.cat((W,H,C),1)\n",
        "        temp = temp.reshape(1,-1)  \n",
        "        calender.append(temp.tolist())\n",
        "    return calender"
      ],
      "metadata": {
        "id": "f7wgwHm05fIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evenly divide the whole dataset into five folds for cross validation\n",
        "test_indice1 = list(range(0,672))+list(range(3360,3360+672))+list(range(3360*2,3360*2+672))+list(range(3360*3,3360*3+672))+list(range(3360*4,3360*4+672))\n",
        "test_indice2 = list(range(672,672*2))+list(range(3360+672,3360+672*2))+list(range(3360*2+672,3360*2+672*2))+list(range(3360*3+672,3360*3+672*2))+list(range(3360*4+672,3360*4+672*2))\n",
        "test_indice3 = list(range(672*2,672*3))+list(range(3360+672*2,3360+672*3))+list(range(3360*2+672*2,3360*2+672*3))+list(range(3360*3+672*2,3360*3+672*3))+list(range(3360*4+672*2,3360*4+672*3))\n",
        "test_indice4 = list(range(672*3,672*4))+list(range(3360+672*3,3360+672*4))+list(range(3360*2+672*3,3360*2+672*4))+list(range(3360*3+672*3,3360*3+672*4))+list(range(3360*4+672*3,3360*4+672*4))\n",
        "test_indice5 = list(range(672*4,672*5))+list(range(3360+672*4,3360+672*5))+list(range(3360*2+672*4,3360*2+672*5))+list(range(3360*3+672*4,3360*3+672*5))+list(range(3360*4+672*4,3360*4+672*5))\n",
        "train_indice = list(range(0,16844))"
      ],
      "metadata": {
        "id": "G_V6o2I88cWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate input features data_X and output labels data_Y\n",
        "data_X, data_Y, data_Z, data_W = Create_dataset(data)\n",
        "data_Y = np.expand_dims(data_Y,2)\n",
        "data_Z = np.array(Calender(torch.tensor(data_Z)))\n",
        "data_Z = np.transpose(data_Z,(0,2,1))\n",
        "data_X = np.concatenate((data_W,data_X,data_Z),1)"
      ],
      "metadata": {
        "id": "9FumTG3G8vHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate training data and testing data respectively for each one of the five folds\n",
        "train_X, test_X = [data_X[index] for index in train_indice if index not in test_indice1], [data_X[index] for index in test_indice1]\n",
        "train_Y, test_Y = [data_Y[index] for index in train_indice if index not in test_indice1], [data_Y[index] for index in test_indice1]\n",
        "train_X, train_Y = np.array(train_X), np.array(train_Y)\n",
        "test_X, test_Y = np.array(test_X), np.array(test_Y)"
      ],
      "metadata": {
        "id": "nCs1Ywjz9KSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Train(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.skip, self.data, self.weather, self.calender, self.label = data[:,:96,:].float(), data[:,96:384,:].float(), data[:,384:1056,:].float(), data[:,1056:2880,:].float(), data[:,-96:,:].float()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.skip[index], self.data[index], self.weather[index], self.calender[index], self.label[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "oeqzvF0v941S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load training data into DataLoader\n",
        "train_loader = DataLoader(Train(torch.cat((torch.tensor(train_X),torch.tensor(train_Y)),1)), batch_size=500, shuffle=True)"
      ],
      "metadata": {
        "id": "GPXS9yrs-Sgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FCNN model\n",
        "class ANN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ANN, self).__init__()\n",
        "        \n",
        "        self.ann = nn.Sequential(\n",
        "            nn.Linear(288,576),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.LayerNorm(576),\n",
        "        )\n",
        "        self.categorical = nn.Sequential(\n",
        "            nn.Linear(26,1),\n",
        "        )\n",
        "        self.skip = nn.Sequential(\n",
        "            nn.Linear(96,576),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.LayerNorm(576),\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(576,96),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.LayerNorm(96),\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, k, x, y, w):\n",
        "        \n",
        "        batch = x.shape[0]\n",
        "        tk = self.skip(k)\n",
        "        tx = self.ann(x)\n",
        "        tx = tx+tk\n",
        "        ty = torch.reshape(y,(batch,96,-1))\n",
        "        tw = torch.reshape(w,(batch,96,-1))\n",
        "        twy = torch.cat((tw,ty),2)\n",
        "        twy = self.categorical(twy)\n",
        "        twy  = torch.transpose(twy,1,2)\n",
        "        tx = self.out(tx)\n",
        "        out = tx+twy\n",
        "        # use relu at final step to generate positive output\n",
        "        out = self.relu(out)  \n",
        "        return out"
      ],
      "metadata": {
        "id": "T2-HKTS9-buK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=1,   \n",
        "            hidden_size=20,\n",
        "            num_layers=2, \n",
        "            batch_first=True,\n",
        "            dropout=0.1,\n",
        "        )\n",
        "        self.categorical = nn.Sequential(\n",
        "            nn.Linear(26,1),\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(20,1),\n",
        "        )\n",
        "        self.state = None\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, k, x, y, w):\n",
        "        \n",
        "        batch = x.shape[0]\n",
        "        tx, self.state = self.lstm(x, state)\n",
        "        ty = torch.reshape(y,(batch,96,-1))\n",
        "        tw = torch.reshape(w,(batch,96,-1))\n",
        "        twy = torch.cat((tw,ty),2)\n",
        "        temp = self.categorical(twy)\n",
        "        tx = self.out(tx[:,-96:,:])\n",
        "        out = tx+temp\n",
        "        # use relu at final step to generate positive output \n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "7go7tZ7HBtJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters for training process\n",
        "LR = 0.01\n",
        "EPOCH = 500\n",
        "Loss = []\n",
        "best_loss = 100\n",
        "state = None\n",
        "cal_loss = nn.MSELoss()"
      ],
      "metadata": {
        "id": "3DhFUkWECbUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training FCNN model\n",
        "model = ANN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR) \n",
        "for i in range(EPOCH):\n",
        "    for j, entry in enumerate(train_loader):\n",
        "        tk, tx, ty, tw, tz = entry\n",
        "        tx = torch.transpose(tx,1,2)\n",
        "        ty = torch.transpose(ty,1,2)\n",
        "        tw = torch.transpose(tw,1,2)\n",
        "        tk = torch.transpose(tk,1,2)\n",
        "        tz = torch.transpose(tz,1,2)\n",
        "        final_out = model(tk,tx,ty,tw)\n",
        "        loss = cal_loss(final_out, tz)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "        Loss.append(loss.detach().numpy())\n",
        "    print('epoch{}'.format(i+1), loss.detach().numpy())\n",
        "    if loss.detach().numpy() < best_loss:\n",
        "        best_loss = loss.detach().numpy()\n",
        "        torch.save(model, 'ithaca_fcnn_load'.format(loss.detach().numpy()))\n",
        "        print('new fcnn saved at epoch {} with loss {}'.format(i+1, best_loss))"
      ],
      "metadata": {
        "id": "TA4SLCmEC_ZH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training LSTM model\n",
        "model = LSTM()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR) \n",
        "for i in range(EPOCH):\n",
        "    for j, entry in enumerate(train_loader):\n",
        "        tk, tx, ty, tw, tz = entry\n",
        "        if state is not None:\n",
        "            state = state.detach()\n",
        "        final_out = model(tx,ty,tw)\n",
        "        loss = cal_loss(final_out, tz)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "        Loss.append(loss.detach().numpy())\n",
        "    print('epoch{}'.format(i+1), loss.detach().numpy())\n",
        "    if loss.detach().numpy() < best_loss:\n",
        "        best_loss = loss.detach().numpy()\n",
        "        torch.save(model, 'ithaca_lstm_load'.format(loss.detach().numpy()))\n",
        "        print('new lstm saved at epoch {} with loss {}'.format(i+1, best_loss))"
      ],
      "metadata": {
        "id": "36bR5_OGDjvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,6))\n",
        "plt.plot(Loss,'b')\n",
        "plt.title('Training Loss for Load',fontsize=15)\n",
        "plt.savefig('training_loss.png')"
      ],
      "metadata": {
        "id": "bers2AotKVNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate prediction for testing set with trained fcnn model\n",
        "model = torch.load('ithaca_fcnn_load')\n",
        "model.eval()\n",
        "test_res = test_X[:,:96,:]\n",
        "test_res = torch.tensor(test_res, dtype=torch.float32)\n",
        "test_res = torch.transpose(test_res,1,2)\n",
        "test_load = test_X[:,96:384,:]\n",
        "test_load = torch.tensor(test_load, dtype=torch.float32)\n",
        "test_load = torch.transpose(test_load,1,2)\n",
        "test_weather = test_X[:,384:1344,:]\n",
        "test_weather = torch.tensor(test_weather, dtype=torch.float32)\n",
        "test_weather = torch.transpose(test_weather,1,2)\n",
        "test_date = test_X[:,1344:,:]\n",
        "test_date = torch.tensor(test_date, dtype=torch.float32)\n",
        "prediction = model(test_res,test_load,test_weather,test_date)\n",
        "torch.save(prediction, 'prediction_load_fcnn.pt')"
      ],
      "metadata": {
        "id": "RKi_myuQ9srr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate prediction for testing set with trained lstm model\n",
        "model = torch.load('ithaca_lstm_load')\n",
        "model.eval()\n",
        "state = None\n",
        "test_res = test_X[:,:96,:]\n",
        "test_res = torch.tensor(test_res, dtype=torch.float32)\n",
        "test_load = test_X[:,96:384,:]\n",
        "test_load = torch.tensor(test_load, dtype=torch.float32)\n",
        "test_weather = test_X[:,384:1344,:]\n",
        "test_weather = torch.tensor(test_weather, dtype=torch.float32)\n",
        "test_date = test_X[:,1344:,:]\n",
        "test_date = torch.tensor(test_date, dtype=torch.float32)\n",
        "prediction = model(test_res, test_load, test_weather, test_date)\n",
        "torch.save(prediction, 'prediction_load_lstm.pt')"
      ],
      "metadata": {
        "id": "RmW-taQa86Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzpeVdCTKglw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}