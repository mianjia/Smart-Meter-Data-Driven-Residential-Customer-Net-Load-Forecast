{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ha2gNdZq2SoB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv ('data_Ithaca.csv')\n",
        "data = df.values\n",
        "# 13th column for ground truth load, 29th column for disaggregated load\n",
        "names = df.columns[[13,10,23,24,25,26,6,27,0,2,22]]\n",
        "print(names)\n",
        "data = data[:,[13,10,23,24,25,26,6,27,0,2,22]]\n",
        "mean_c, std_c, min_c, max_c = np.mean(data[:,0]), np.std(data[:,0]), np.min(data[:,0]), np.max(data[:,0])\n",
        "print('mean',mean_c, 'std',std_c, 'max',max_c, 'min',min_c)\n",
        "# normalize entire dataset to [0,1]\n",
        "data[:,0] = (data[:,0]-min_c)/(max_c-min_c)\n",
        "data = data.astype('float32')\n",
        "for i in [1,2,3,4,5,6,7]:\n",
        "    min_temp, max_temp = np.min(data[:,i]), np.max(data[:,i]) \n",
        "    data[:,i] = (data[:,i]-min_temp)/(max_temp-min_temp)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2KHgxBZ2dKM",
        "outputId": "987c586a-459a-4cdb-e92f-b036fc7cdc8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['consumption', 'Temperature', 'Dew Point', 'Wind Speed.1',\n",
            "       'Precipitable Water', 'Relative humidity', 'zenith', 'Pressure',\n",
            "       'weekday', 'timeslot of day', 'Cloud Type'],\n",
            "      dtype='object')\n",
            "mean 10.385668138586956 std 4.49667223574142 max 37.726 min 3.298\n",
            "(17664, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# employ sliding window to stack data correspondingly\n",
        "def Create_dataset(dataset):\n",
        "    data_X, data_Y, data_Z, data_W = [], [], [], []\n",
        "    dt = dataset.tolist()\n",
        "    for i in range(len(dataset)-820): \n",
        "        indice = list(range(i,i+96))+list(range(i+96*5,i+96*7))\n",
        "        tempx = np.array([dt[index] for index in indice])\n",
        "        tempy = dataset[i+724:i+820,:]\n",
        "        tempw = dataset[i:i+96,:]\n",
        "        temp1 = tempx[:,0].reshape(-1,1)\n",
        "        temp2 = tempy[:,1:8].reshape(-1,1)\n",
        "        temp3 = np.concatenate((temp1,temp2)).tolist()\n",
        "        temp4 = tempy[:,0].tolist()\n",
        "        temp5 = tempy[:,8:].reshape(-1,1)\n",
        "        temp6 = tempw[:,0].reshape(-1,1)\n",
        "       \n",
        "        data_W.append(temp6) # load traces from the day one week ago\n",
        "        data_X.append(temp3) # load traces from the past two days and numerical weather forecast\n",
        "        data_Y.append(temp4) # targeted load traces (13 hours ahead ~ 37 hours ahead)\n",
        "        data_Z.append(temp5) # categorical features\n",
        "    \n",
        "    return np.array(data_X), np.array(data_Y), np.array(data_Z), np.array(data_W)"
      ],
      "metadata": {
        "id": "-zc2kFMW2uiM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode categorical input features\n",
        "one_hot = lambda label,num_classes: F.one_hot(label.long(), num_classes=num_classes).type(torch.float32)\n",
        "cycl_ = lambda x,num_classes : torch.tensor((np.sin(x / num_classes * 2 * np.pi),np.cos(x / num_classes * 2 * np.pi))).type(torch.float32)\n",
        "\n",
        "def Calender(data):\n",
        "    calender = []\n",
        "    for i in range(data.shape[0]):\n",
        "        ty = data[i]\n",
        "        temp = torch.zeros(96,19)\n",
        "        for j in range(96):\n",
        "            W = one_hot(ty[3*j]-1,7)                   # weekday\n",
        "            H = torch.unsqueeze(cycl_(ty[3*j+1],24),0) # timeslot of the day\n",
        "            C = one_hot(ty[3*j+2],10)                  # cloud type\n",
        "            temp[j,:] = torch.cat((W,H,C),1)\n",
        "        temp = temp.reshape(1,-1)  \n",
        "        calender.append(temp.tolist())\n",
        "    return calender"
      ],
      "metadata": {
        "id": "f7wgwHm05fIn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evenly divide the whole dataset into five folds for cross validation\n",
        "test_indice1 = list(range(0,672))+list(range(3360,3360+672))+list(range(3360*2,3360*2+672))+list(range(3360*3,3360*3+672))+list(range(3360*4,3360*4+672))\n",
        "test_indice2 = list(range(672,672*2))+list(range(3360+672,3360+672*2))+list(range(3360*2+672,3360*2+672*2))+list(range(3360*3+672,3360*3+672*2))+list(range(3360*4+672,3360*4+672*2))\n",
        "test_indice3 = list(range(672*2,672*3))+list(range(3360+672*2,3360+672*3))+list(range(3360*2+672*2,3360*2+672*3))+list(range(3360*3+672*2,3360*3+672*3))+list(range(3360*4+672*2,3360*4+672*3))\n",
        "test_indice4 = list(range(672*3,672*4))+list(range(3360+672*3,3360+672*4))+list(range(3360*2+672*3,3360*2+672*4))+list(range(3360*3+672*3,3360*3+672*4))+list(range(3360*4+672*3,3360*4+672*4))\n",
        "test_indice5 = list(range(672*4,672*5))+list(range(3360+672*4,3360+672*5))+list(range(3360*2+672*4,3360*2+672*5))+list(range(3360*3+672*4,3360*3+672*5))+list(range(3360*4+672*4,3360*4+672*5))\n",
        "train_indice = list(range(0,16844))"
      ],
      "metadata": {
        "id": "G_V6o2I88cWD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate input features data_X and output labels data_Y\n",
        "data_X, data_Y, data_Z, data_W = Create_dataset(data)\n",
        "data_Y = np.expand_dims(data_Y,2)\n",
        "data_Z = np.array(Calender(torch.tensor(data_Z)))\n",
        "data_Z = np.transpose(data_Z,(0,2,1))\n",
        "data_X = np.concatenate((data_W,data_X,data_Z),1)"
      ],
      "metadata": {
        "id": "9FumTG3G8vHF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate training data and testing data respectively for each one of the five folds\n",
        "train_X, test_X = [data_X[index] for index in train_indice if index not in test_indice1], [data_X[index] for index in test_indice1]\n",
        "train_Y, test_Y = [data_Y[index] for index in train_indice if index not in test_indice1], [data_Y[index] for index in test_indice1]\n",
        "train_X, train_Y = np.array(train_X), np.array(train_Y)\n",
        "test_X, test_Y = np.array(test_X), np.array(test_Y)"
      ],
      "metadata": {
        "id": "nCs1Ywjz9KSU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Train(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.skip, self.data, self.weather, self.calender, self.label = data[:,:96,:].float(), data[:,96:384,:].float(), data[:,384:1056,:].float(), data[:,1056:2880,:].float(), data[:,-96:,:].float()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.skip[index], self.data[index], self.weather[index], self.calender[index], self.label[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "oeqzvF0v941S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load training data into DataLoader\n",
        "train_loader = DataLoader(Train(torch.cat((torch.tensor(train_X),torch.tensor(train_Y)),1)), batch_size=500, shuffle=True)"
      ],
      "metadata": {
        "id": "GPXS9yrs-Sgk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FCNN model\n",
        "class ANN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ANN, self).__init__()\n",
        "        \n",
        "        self.ann = nn.Sequential(\n",
        "            nn.Linear(288,576),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.LayerNorm(576),\n",
        "        )\n",
        "        self.categorical = nn.Sequential(\n",
        "            nn.Linear(26,1),\n",
        "        )\n",
        "        self.skip = nn.Sequential(\n",
        "            nn.Linear(96,576),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.LayerNorm(576),\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(576,96),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.LayerNorm(96),\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, k, x, y, w):\n",
        "        \n",
        "        batch = x.shape[0]\n",
        "        tk = self.skip(k)\n",
        "        tx = self.ann(x)\n",
        "        tx = tx+tk\n",
        "        ty = torch.reshape(y,(batch,96,-1))\n",
        "        tw = torch.reshape(w,(batch,96,-1))\n",
        "        twy = torch.cat((tw,ty),2)\n",
        "        twy = self.categorical(twy)\n",
        "        twy  = torch.transpose(twy,1,2)\n",
        "        tx = self.out(tx)\n",
        "        out = tx+twy\n",
        "        # use relu at final step to generate positive output\n",
        "        out = self.relu(out)  \n",
        "        return out"
      ],
      "metadata": {
        "id": "T2-HKTS9-buK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=1,   \n",
        "            hidden_size=20,\n",
        "            num_layers=2, \n",
        "            batch_first=True,\n",
        "            dropout=0.1,\n",
        "        )\n",
        "        self.categorical = nn.Sequential(\n",
        "            nn.Linear(26,1),\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(20,1),\n",
        "        )\n",
        "        self.state = None\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, k, x, y, w):\n",
        "        \n",
        "        batch = x.shape[0]\n",
        "        tx, self.state = self.lstm(x, state)\n",
        "        ty = torch.reshape(y,(batch,96,-1))\n",
        "        tw = torch.reshape(w,(batch,96,-1))\n",
        "        twy = torch.cat((tw,ty),2)\n",
        "        temp = self.categorical(twy)\n",
        "        tx = self.out(tx[:,-96:,:])\n",
        "        out = tx+temp\n",
        "        # use relu at final step to generate positive output \n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "7go7tZ7HBtJj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameters for training process\n",
        "LR = 0.01\n",
        "EPOCH = 500\n",
        "Loss = []\n",
        "best_loss = 100\n",
        "state = None\n",
        "cal_loss = nn.MSELoss()"
      ],
      "metadata": {
        "id": "3DhFUkWECbUL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training FCNN model\n",
        "model = ANN()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR) \n",
        "for i in range(EPOCH):\n",
        "    for j, entry in enumerate(train_loader):\n",
        "        tk, tx, ty, tw, tz = entry\n",
        "        tx = torch.transpose(tx,1,2)\n",
        "        ty = torch.transpose(ty,1,2)\n",
        "        tw = torch.transpose(tw,1,2)\n",
        "        tk = torch.transpose(tk,1,2)\n",
        "        tz = torch.transpose(tz,1,2)\n",
        "        final_out = model(tk,tx,ty,tw)\n",
        "        loss = cal_loss(final_out, tz)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "        Loss.append(loss.detach().numpy())\n",
        "    print('epoch{}'.format(i+1), loss.detach().numpy())\n",
        "    if loss.detach().numpy() < best_loss:\n",
        "        best_loss = loss.detach().numpy()\n",
        "        torch.save(model, 'ithaca_fcnn_load'.format(loss.detach().numpy()))\n",
        "        print('new fcnn saved at epoch {} with loss {}'.format(i+1, best_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "TA4SLCmEC_ZH",
        "outputId": "d22a1c32-feac-413f-9154-c9b1c2d95048"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch1 0.055029094\n",
            "new fcnn saved at epoch 1 with loss 0.055029094219207764\n",
            "epoch2 0.055427447\n",
            "epoch3 0.05064194\n",
            "new fcnn saved at epoch 3 with loss 0.05064193904399872\n",
            "epoch4 0.047128253\n",
            "new fcnn saved at epoch 4 with loss 0.04712825268507004\n",
            "epoch5 0.04629001\n",
            "new fcnn saved at epoch 5 with loss 0.04629001021385193\n",
            "epoch6 0.042683546\n",
            "new fcnn saved at epoch 6 with loss 0.042683545500040054\n",
            "epoch7 0.04152984\n",
            "new fcnn saved at epoch 7 with loss 0.04152984172105789\n",
            "epoch8 0.03831702\n",
            "new fcnn saved at epoch 8 with loss 0.03831702098250389\n",
            "epoch9 0.037422366\n",
            "new fcnn saved at epoch 9 with loss 0.03742236644029617\n",
            "epoch10 0.03453983\n",
            "new fcnn saved at epoch 10 with loss 0.034539829939603806\n",
            "epoch11 0.032338835\n",
            "new fcnn saved at epoch 11 with loss 0.032338835299015045\n",
            "epoch12 0.032800484\n",
            "epoch13 0.030929783\n",
            "new fcnn saved at epoch 13 with loss 0.03092978335916996\n",
            "epoch14 0.031030685\n",
            "epoch15 0.029298244\n",
            "new fcnn saved at epoch 15 with loss 0.029298244044184685\n",
            "epoch16 0.028805098\n",
            "new fcnn saved at epoch 16 with loss 0.028805097565054893\n",
            "epoch17 0.027404623\n",
            "new fcnn saved at epoch 17 with loss 0.027404623106122017\n",
            "epoch18 0.027970076\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-89bcb8e607b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training LSTM model\n",
        "model = LSTM()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR) \n",
        "for i in range(EPOCH):\n",
        "    for j, entry in enumerate(train_loader):\n",
        "        tk, tx, ty, tw, tz = entry\n",
        "        if state is not None:\n",
        "            state = state.detach()\n",
        "        final_out = model(tx,ty,tw)\n",
        "        loss = cal_loss(final_out, tz)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "        Loss.append(loss.detach().numpy())\n",
        "    print('epoch{}'.format(i+1), loss.detach().numpy())\n",
        "    if loss.detach().numpy() < best_loss:\n",
        "        best_loss = loss.detach().numpy()\n",
        "        torch.save(model, 'ithaca_lstm_load'.format(loss.detach().numpy()))\n",
        "        print('new lstm saved at epoch {} with loss {}'.format(i+1, best_loss))"
      ],
      "metadata": {
        "id": "36bR5_OGDjvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,6))\n",
        "plt.plot(Loss,'b')\n",
        "plt.title('Training Loss for Load',fontsize=15)\n",
        "plt.savefig('training_loss.png')"
      ],
      "metadata": {
        "id": "bers2AotKVNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate prediction for testing set with trained fcnn model\n",
        "model = torch.load('ithaca_fcnn_load')\n",
        "model.eval()\n",
        "test_res = test_X[:,:96,:]\n",
        "test_res = torch.tensor(test_res, dtype=torch.float32)\n",
        "test_res = torch.transpose(test_res,1,2)\n",
        "test_load = test_X[:,96:384,:]\n",
        "test_load = torch.tensor(test_load, dtype=torch.float32)\n",
        "test_load = torch.transpose(test_load,1,2)\n",
        "test_weather = test_X[:,384:1344,:]\n",
        "test_weather = torch.tensor(test_weather, dtype=torch.float32)\n",
        "test_weather = torch.transpose(test_weather,1,2)\n",
        "test_date = test_X[:,1344:,:]\n",
        "test_date = torch.tensor(test_date, dtype=torch.float32)\n",
        "prediction = model(test_res,test_load,test_weather,test_date)\n",
        "torch.save(prediction, 'prediction_load_fcnn.pt')"
      ],
      "metadata": {
        "id": "RKi_myuQ9srr"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate prediction for testing set with trained lstm model\n",
        "model = torch.load('ithaca_lstm_load')\n",
        "model.eval()\n",
        "state = None\n",
        "test_res = test_X[:,:96,:]\n",
        "test_res = torch.tensor(test_res, dtype=torch.float32)\n",
        "test_load = test_X[:,96:384,:]\n",
        "test_load = torch.tensor(test_load, dtype=torch.float32)\n",
        "test_weather = test_X[:,384:1344,:]\n",
        "test_weather = torch.tensor(test_weather, dtype=torch.float32)\n",
        "test_date = test_X[:,1344:,:]\n",
        "test_date = torch.tensor(test_date, dtype=torch.float32)\n",
        "prediction = model(test_res, test_load, test_weather, test_date)\n",
        "torch.save(prediction, 'prediction_load_lstm.pt')"
      ],
      "metadata": {
        "id": "RmW-taQa86Vr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzpeVdCTKglw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}